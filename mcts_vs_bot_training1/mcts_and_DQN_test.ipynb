{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "\n",
    "import env.chess_env as chess_env\n",
    "from DQN.net_function_tf_k import creat_network_3d\n",
    "from DQN.DQN_player import DQN_Bot\n",
    "from env.move_func import make_move, available_move\n",
    "from DQN.deep_q_network import DeepQNetwork\n",
    "\n",
    "\n",
    "optimizer1 = tf.train.RMSPropOptimizer(learning_rate=0.0001, decay=0.9)\n",
    "optimizer2 = tf.train.AdamOptimizer(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_choose_move(action):\n",
    "    #valid_move = available_move(list(env.board.legal_moves))\n",
    "    #print(valid_move)\n",
    "    #a = input(\"inter the move  :\")\n",
    "    make_move(env, str(a))\n",
    "    print(env.board)\n",
    "\n",
    "def play_bot_to_bot(env):\n",
    "    b = DQN_Bot(creat_network_3d, optimizer1)\n",
    "    b2 = DQN_Bot(creat_network_3d, optimizer2)\n",
    "    \n",
    "    while env.board.result() == \"*\":\n",
    "        print(env.board)\n",
    "        if env.white_to_move:\n",
    "            action = b.choose_move(env)\n",
    "        else:\n",
    "            action = b2.choose_move(env)\n",
    "        print(action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_human_to_bot(env, p):\n",
    "    sess = sess = tf.Session()\n",
    "    '''q_network1 = DeepQNetwork(sess,\n",
    "                             optimizer1,\n",
    "                             creat_network_3d,\n",
    "                             state_dim = (18,8,8) ,\n",
    "                             num_actions = 1968,\n",
    "                             batch_size=32,\n",
    "                             init_exp=0.6,         # initial exploration prob\n",
    "                             final_exp=0.01,   #0.1     # final exploration prob\n",
    "                             anneal_steps=120000,  # N steps for annealing exploration\n",
    "                             double_q_learning=True,\n",
    "                             discount_factor=0.8)'''\n",
    "\n",
    "    training_episodes = 200000\n",
    "    black_path =\"models/black_ckpts_at\" + str(training_episodes)+ \"steps/\"\n",
    "    #optimizer1 = tf.train.RMSPropOptimizer(learning_rate=0.0001, decay=0.9)\n",
    "    b = DQN_Bot(creat_network_3d, optimizer1,sess,black_path)\n",
    "\n",
    "    if p == \"WHITE\":\n",
    "        while env.board.result() == \"*\":\n",
    "            print(env.board)\n",
    "            if env.white_to_move:\n",
    "                print(\"white player move\")\n",
    "                bl_path =\"models/white_ckpts_at\" + str(training_episodes)+ \"steps/\"\n",
    "                b1=DQN_Bot( creat_network_3d, optimizer1, sess,b1_path)\n",
    "                env = chess_env.ChessEnv()\n",
    "                b = MCTSPlayer(evaluate)\n",
    "                action, probs = b.get_action(env, b1)\n",
    "                human_choose_move(env, action)\n",
    "                \n",
    "            else:\n",
    "                action = b.choose_move(env)\n",
    "                print(action)\n",
    "\n",
    "    else:\n",
    "        while env.board.result() == \"*\":\n",
    "            print(env.board)\n",
    "            if env.black_to_move:\n",
    "                b1=DQN_Bot( creat_network_3d, optimizer1, sess1,b1_path)\n",
    "                env = chess_env.ChessEnv()\n",
    "                b = MCTSPlayer(evaluate)\n",
    "                action, probs = b.get_action(env, b1)\n",
    "                human_choose_move(env, action)\n",
    "            else:\n",
    "                action =b.choose_move(env)\n",
    "                print(action)\n",
    "    \n",
    "\n",
    "\n",
    "def play_human_to_human(env, p):\n",
    "    if p == \"WHITE\":\n",
    "        while env.board.result() == \"*\":\n",
    "            print(env.board)\n",
    "            if env.white_to_move:\n",
    "                print(\"white player move\")\n",
    "                human_choose_move(env)\n",
    "                \n",
    "            else:\n",
    "                print(\"Black player move\")\n",
    "                human_choose_move(env)\n",
    "\n",
    "    else:\n",
    "        while env.board.result() == \"*\":\n",
    "            print(env.board)\n",
    "            if env.black_to_move:\n",
    "                print(\"black player move\")\n",
    "                human_choose_move(env)\n",
    "\n",
    "            else:\n",
    "                print(\"white player move\")\n",
    "                human_choose_move(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to B vs H\n",
      "Select Your Player    :white\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:94: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "DOne wth residul block\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\net_function_tf_k.py:69: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:100: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:112: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "DOne wth residul block\n",
      "DOne wth residul block\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:149: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_1/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_1/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_1/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_1/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_1/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_1/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_2/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_2/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_2/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_2/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_2/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_2/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_2/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_3/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_3/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_3/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_3/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_3/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_3/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_3/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_4/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_4/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_4/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_4/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_4/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_4/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_4/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_5/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_5/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_5/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_5/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_5/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_5/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_5/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_6/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_6/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_6/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_6/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_6/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_6/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_6/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_6/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_7/kernel:0 is illegal; using predict_actions/q_network/q_network/conv2d_7/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/conv2d_7/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/conv2d_7/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_7/beta:0 is illegal; using predict_actions/q_network/q_network/batch_normalization_7/beta_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/batch_normalization_7/beta:0/gradients is illegal; using predict_actions/q_network/q_network/batch_normalization_7/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/policy_head/kernel:0 is illegal; using predict_actions/q_network/q_network/policy_head/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/policy_head/kernel:0/gradients is illegal; using predict_actions/q_network/q_network/policy_head/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name q_network/q_network/Wo:0 is illegal; using q_network/q_network/Wo_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name q_network/q_network/Wo:0/gradients is illegal; using q_network/q_network/Wo_0/gradients instead.\n",
      "INFO:tensorflow:Summary name q_network/q_network/bo:0 is illegal; using q_network/q_network/bo_0 instead.\n",
      "INFO:tensorflow:Summary name q_network/q_network/bo:0/gradients is illegal; using q_network/q_network/bo_0/gradients instead.\n",
      "INFO:tensorflow:Summary name predict_actions/q_network/q_network/value_head/kernel:0 is illegal; using predict_actions/q_network/q_network/value_head/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_8/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_8/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_8/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_8/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_9/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_9/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_9/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_9/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_10/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_10/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_10/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_10/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_11/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_11/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_11/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_12/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_12/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_12/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_12/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_13/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_13/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_13/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_13/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_14/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_14/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_14/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_14/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/conv2d_15/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/conv2d_15/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/batch_normalization_15/beta:0 is illegal; using estimate_future_rewards/q_network/q_network/batch_normalization_15/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/policy_head/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/policy_head/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/q_network/q_network/value_head/kernel:0 is illegal; using estimate_future_rewards/q_network/q_network/value_head/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_16/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_16/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_16/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_16/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_16/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_16/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_16/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_16/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_17/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_17/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_17/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_17/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_17/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_17/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_17/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_17/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_18/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_18/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_18/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_18/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_18/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_18/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_18/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_18/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_19/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_19/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_19/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_19/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_19/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_19/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_19/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_19/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_20/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_20/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_20/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_20/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_20/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_20/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_20/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_20/beta_0/gradients instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_21/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_21/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_21/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_21/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_21/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_21/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_21/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_21/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_22/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_22/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_22/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_22/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_22/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_22/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_22/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_22/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_23/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/conv2d_23/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/conv2d_23/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/conv2d_23/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_23/beta:0 is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_23/beta_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/batch_normalization_23/beta:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/batch_normalization_23/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/policy_head/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/policy_head/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/policy_head/kernel:0/gradients is illegal; using estimate_future_rewards/target_network/target_network/policy_head/kernel_0/gradients instead.\n",
      "INFO:tensorflow:Summary name target_network/target_network/Wo:0 is illegal; using target_network/target_network/Wo_0 instead.\n",
      "INFO:tensorflow:Summary name target_network/target_network/Wo:0/gradients is illegal; using target_network/target_network/Wo_0/gradients instead.\n",
      "INFO:tensorflow:Summary name target_network/target_network/bo:0 is illegal; using target_network/target_network/bo_0 instead.\n",
      "INFO:tensorflow:Summary name target_network/target_network/bo:0/gradients is illegal; using target_network/target_network/bo_0/gradients instead.\n",
      "INFO:tensorflow:Summary name estimate_future_rewards/target_network/target_network/value_head/kernel:0 is illegal; using estimate_future_rewards/target_network/target_network/value_head/kernel_0 instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:178: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\dqn_V.py:183: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Desktop\\chess\\mcts_vs_bot_training\\DQN\\DQN_player.py:44: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Irfan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    }
   ],
   "source": [
    "env = chess_env.ChessEnv()\n",
    "env.reset()    \n",
    "print(\"Welcome to B vs H\")\n",
    "p = input(\"Select Your Player    :\")\n",
    "p = str.upper(p)\n",
    "player = [\"WHITE\", \"BLACK\"]\n",
    "if p == player[1]:\n",
    "#                env.change_turn(player[1])\n",
    "    play_human_to_bot(env, p)\n",
    "else:\n",
    "#                env.change_turn(player[0])\n",
    "    play_human_to_bot(env ,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env.chess_env as chess_env\n",
    "from DQN.net_function_tf_k  import creat_network_3d\n",
    "from DQN.DQN_player import DQN_Bot\n",
    "import os , random\n",
    "import tensorflow as tf\n",
    "#from DQN.dqn_V import DeepQNetwork\n",
    "from mcts import MCTSPlayer, evaluate\n",
    "\n",
    "def choose_random_moves(moves: list) -> str:\n",
    "    return random.choice(moves)\n",
    "def choose_move(possible_moves: list) -> str:\n",
    "        return choose_random_moves(possible_moves)\n",
    "def play_bot_to_bot(env, player1, player2):\n",
    "   \"\"\"white is player1\n",
    "    black is player2\"\"\"\n",
    "   while env.board.result() == \"*\":\n",
    "#        print(env.board)\n",
    "        if env.white_to_move:\n",
    "            action = player1.choose_move(env)\n",
    "        else:\n",
    "            action = player2.choose_move(env)\n",
    "training_episodes = 200000\n",
    "game_draw=White=Black=0\n",
    "cent_episode = []\n",
    "b1_path= \"models/b1_ckpts_at\" + str(training_episodes) + \"steps/\"\n",
    "b2_path = \"models/b2_ckpts_at\" + str(training_episodes) + \"steps/\"\n",
    "if not os.path.exists(b1_path) :\n",
    "    os.mkdir(b1_path)\n",
    "if not os.path.exists(b2_path) :\n",
    "    os.mkdir(b2_path)\n",
    "sess1 = tf.Session()\n",
    "\n",
    "optimizer1 = tf.train.RMSPropOptimizer(learning_rate=0.0001, decay=0.9)\n",
    "b1=DQN_Bot( creat_network_3d, optimizer1, sess1,b1_path)\n",
    "env = chess_env.ChessEnv()\n",
    "b = MCTSPlayer(evaluate)\n",
    "action, probs = b.get_action(env, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to B vs H\n",
      "Select Your Player    :white\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'optimizer1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-36fff284cd67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#                env.change_turn(player[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mplay_human_to_bot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-8293145aed25>\u001b[0m in \u001b[0;36mplay_human_to_bot\u001b[1;34m(env, p)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtraining_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mblack_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"models/black_ckpts_at\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"steps/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN_Bot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreat_network_3d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblack_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"WHITE\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'optimizer1' referenced before assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_bot_to_bot(env, player1, player2):\n",
    "   \"\"\"white is player1\n",
    "    black is player2\"\"\"\n",
    "   while env.board.result() == \"*\":\n",
    "#        print(env.board)\n",
    "        if env.white_to_move:\n",
    "            action = player1.choose_move(env)\n",
    "        else:\n",
    "            action = player2.choose_move(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = chess_env.ChessEnv()\n",
    "    env.reset()\n",
    "    def select():\n",
    "        print(\"1:- Game play with human to human  : \")\n",
    "        print(\"2:- Game play with Bot to Human  : \")\n",
    "        print(\"3:- Game play with Bot to Bot  : \")\n",
    "        check = int(input(\"Select number for play:  \"))\n",
    "        if check == 1:\n",
    "            print(\"welcome to H vs H\")\n",
    "            p = input(\"Select Your Player   :\")\n",
    "            p = str.upper(p)\n",
    "            player = [\"WHITE\", \"BLACK\"]\n",
    "            if p == player[1]:\n",
    "                env.change_turn(player[1])\n",
    "                play_human_to_human(env, p)\n",
    "            else:\n",
    "                env.change_turn(player[0])\n",
    "                play_human_to_human(env, p)\n",
    "        elif check == 2:\n",
    "            print(\"Welcome to B vs H\")\n",
    "            p = input(\"Select Your Player    :\")\n",
    "            p = str.upper(p)\n",
    "            player = [\"WHITE\", \"BLACK\"]\n",
    "            if p == player[1]:\n",
    "#                env.change_turn(player[1])\n",
    "                play_human_to_bot(env, p)\n",
    "            else:\n",
    "#                env.change_turn(player[0])\n",
    "                play_human_to_bot(env ,p)\n",
    "        elif check == 3:\n",
    "            print(\"Welcome to B vs B\")\n",
    "            play_bot_to_bot(env)\n",
    "            \n",
    "        else:\n",
    "            print(\"Plase select correct number\")\n",
    "            select()\n",
    "    select()    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
